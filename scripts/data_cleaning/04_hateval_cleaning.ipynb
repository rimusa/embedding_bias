{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean HatEval\n",
    "\n",
    "This is a script to clean the HatEval dataset and to separate it into the two different tasks that we will be using it for. I'm assuming that it is saved to ``data/hateval2019``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We establish the path to our data and the generic name that our preprocessed datasets have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/hateval2019/\"\n",
    "files = \"hateval2019_clean_es_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first task is hate speech detection, so we only keep the HS label from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"train\",\"dev\",\"test\"]:\n",
    "    df = pd.read_csv(path+files+i+\".csv\")\n",
    "    \n",
    "    task1 = df[[\"id\",\"text\",\"HS\"]]\n",
    "    task1.columns = [\"id\",\"text\",\"label\"]\n",
    "    task1.to_csv(path+\"task1_es_\"+i+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second task requires us to only consider hate Tweets. Here we have to determine whether they are targeted or not and if they are agressive or not. We decided to make this task a multilabel classification task instead of a multiclass one, so we set the following labels:\n",
    "1. Neither targeted nor agressive\n",
    "1. Agressive but not targeted\n",
    "1. Targeted but not agressive\n",
    "1. Targeted and agressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"train\",\"dev\",\"test\"]:\n",
    "    df = pd.read_csv(path+files+i+\".csv\")\n",
    "    \n",
    "    task2 = df[[\"id\",\"text\",\"TR\",\"AG\"]].loc[df[\"HS\"]==1]\n",
    "    task2[\"label\"] = 0\n",
    "    task2[\"label\"].loc[(task2.TR == 0) & (task2.AG == 1)] = 1\n",
    "    task2[\"label\"].loc[(task2.TR == 1) & (task2.AG == 0)] = 2\n",
    "    task2[\"label\"].loc[(task2.TR == 1) & (task2.AG == 1)] = 3\n",
    "    print(task2.label.unique())\n",
    "    task2 = task2.drop([\"TR\",\"AG\"],axis=1)\n",
    "    task2.to_csv(path+\"task2_es_\"+i+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
