{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualization\n",
    "\n",
    "This is the file I used to load and visualize my results.\n",
    "\n",
    "We first import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we set the results paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../results/\"\n",
    "cnn_path = path + \"cnn/\"\n",
    "weat_path = path + \"xweat/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the results of a single run of the CNN and returns a dictionary with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_HatEval_results(path, file, name):\n",
    "\n",
    "    data = list(map(\n",
    "                    lambda x: x.strip().lower().split(),\n",
    "                    open(path+file,\"r\", encoding=\"utf8\").readlines()\n",
    "                   ))\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for item in data:\n",
    "        key = name + \"_\" + item[0][:-1]\n",
    "        results[key] = item[1]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads all of the results of the CNN and returns them as dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn1_results(embed, path, previous_data=None):\n",
    "    if previous_data is None:\n",
    "        exp_results = {}\n",
    "    else:\n",
    "        exp_results = previous_data\n",
    "    for test in [None, 1,2,6,7,8,9]:\n",
    "        if test is not None:\n",
    "            mods = [\"more\", \"less\"]\n",
    "        else:\n",
    "            mods = [\"\"]\n",
    "        for mod in mods:\n",
    "            task = \"1\"\n",
    "            n =  \"Task\" + task\n",
    "            for group in [\"\",\"g1\",\"g2\"]:\n",
    "                name = n\n",
    "                file = \"task\" + task + \"_\" + embed\n",
    "                if test is not None:\n",
    "                    file += \"_t\" + str(test) + \"_\" + mod\n",
    "                if group != \"\":\n",
    "                    file += \"_\" + group\n",
    "                file += \".txt\"\n",
    "                #print(file)\n",
    "                if test is None:\n",
    "                    embedding = embed + \"_Unmod\"\n",
    "                else:\n",
    "                    embedding = embed + \"_Test\" + str(test) + \"_\" + mod\n",
    "                if group != \"\":\n",
    "                    name += \"_\" + group\n",
    "                results = read_HatEval_results(path,file,name)\n",
    "                if embedding not in exp_results.keys():\n",
    "                    exp_results[embedding] = {}\n",
    "                for key in results:\n",
    "                    exp_results[embedding][key] = results[key]\n",
    "            \n",
    "            key = n+\"_EqOpp\"\n",
    "            exp_results[embedding][key] = str(float(exp_results[embedding][\"Task1_g1_recall\"]) - float(exp_results[embedding][\"Task1_g2_recall\"])) \n",
    "            key = n+\"_DiffPr\"\n",
    "            exp_results[embedding][key] = str(float(exp_results[embedding][\"Task1_g1_precision\"]) - float(exp_results[embedding][\"Task1_g2_precision\"])) \n",
    "\n",
    "    return exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the results of a single run of the CNN2 (subtask B of HatEval) and returns a dictionsry with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_HatEval_results_B(path, file, name):\n",
    "\n",
    "    data = list(map(\n",
    "                    lambda x: x.strip().lower().split(),\n",
    "                    open(path+file,\"r\", encoding=\"utf8\").readlines()\n",
    "                   ))\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    network = \"\"\n",
    "    \n",
    "    for i,item in enumerate(data):\n",
    "        if i%5==0:\n",
    "            network = item[0]\n",
    "            continue\n",
    "        key = name + \"_\" + network + \"_\" + item[0][:-1]\n",
    "        results[key] = item[1]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads all of the results from the CNN2 and returns their dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn2_results(embed, path, previous_data=None):\n",
    "    if previous_data is None:\n",
    "        exp_results = {}\n",
    "    else:\n",
    "        exp_results = previous_data\n",
    "    for test in [None, 1,2,6,7,8,9]:\n",
    "        if test is not None:\n",
    "            mods = [\"more\", \"less\"]\n",
    "        else:\n",
    "            mods = [\"\"]\n",
    "        for mod in mods:\n",
    "            task = \"2\"\n",
    "            n =  \"Task\" + task\n",
    "            for group in [\"\",\"g1\",\"g2\"]:\n",
    "                file = \"task\" + task + \"_\" + embed\n",
    "                if test is not None:\n",
    "                    file += \"_t\" + str(test) + \"_\" + mod\n",
    "                if group != \"\":\n",
    "                    file += \"_\" + group\n",
    "                file += \".txt\"\n",
    "                #print(file)\n",
    "                if test is None:\n",
    "                    embedding = embed + \"_Unmod\"\n",
    "                else:\n",
    "                    embedding = embed + \"_Test\" + str(test) + \"_\" + mod\n",
    "                name = n\n",
    "                if group != \"\":\n",
    "                    name += \"_\" + group\n",
    "                results = read_HatEval_results_B(path,file,name)\n",
    "                if embedding not in exp_results.keys():\n",
    "                    exp_results[embedding] = {}\n",
    "                for key in results:\n",
    "                    exp_results[embedding][key] = results[key]\n",
    "               \n",
    "            EO = 0\n",
    "            DP = 0\n",
    "            for label in [\"hs\",\"tr\",\"ag\"]:\n",
    "                key = n+\"_\"+label+\"_EqOpp\"\n",
    "                exp_results[embedding][key] = str(float(exp_results[embedding][\"Task2_g1_\"+label+\"_recall\"]) - float(exp_results[embedding][\"Task2_g2_\"+label+\"_recall\"])) \n",
    "                EO += float(exp_results[embedding][key])\n",
    "                key = n+\"_\"+label+\"_DiffPr\"\n",
    "                exp_results[embedding][key] = str(float(exp_results[embedding][\"Task2_g1_\"+label+\"_precision\"]) - float(exp_results[embedding][\"Task2_g2_\"+label+\"_precision\"])) \n",
    "                DP += float(exp_results[embedding][key])\n",
    "                \n",
    "            exp_results[embedding][n+\"_EqOpp\"] = EO / 3\n",
    "            exp_results[embedding][n+\"_DiffPr\"] = DP / 3\n",
    "            \n",
    "\n",
    "    return exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This imports the results from a single WEAT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_weat_results(path, file, name):\n",
    "\n",
    "    data = list(map(\n",
    "                        lambda x: x.strip().lower().split(),\n",
    "                        open(path+file,\"r\", encoding=\"utf8\").readlines()\n",
    "                       ))\n",
    "    \n",
    "    results = {\n",
    "               name+\"_WeatStatistic\": float(data[1][1][1:-1]),\n",
    "               name+\"_EffectSize\":    float(data[1][2][:-1]),\n",
    "               name+\"_pValue\":        float(data[1][3][:-1]),\n",
    "              }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This imports the results from all of the WEAT tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weat_results(embed, path, previous_data=None):\n",
    "    \n",
    "    if previous_data is None:\n",
    "        exp_results = {}\n",
    "    else:\n",
    "        exp_results = previous_data\n",
    "        \n",
    "    for test_mod in [None, 1,2,6,7,8,9]:\n",
    "        if test_mod is not None:\n",
    "            mods = [\"more\", \"less\"]\n",
    "        else:\n",
    "            mods = [\"\"]\n",
    "        for mod in mods:\n",
    "            for curr_test in [1,2,6,7,8,9]:\n",
    "                \n",
    "                file = embed\n",
    "                if test_mod is not None:\n",
    "                    file += \"_t\" + str(test_mod) + \"_\" + mod\n",
    "                file += \"_test\" + str(curr_test) + \"_cased.res\"\n",
    "                \n",
    "                if test_mod is None:\n",
    "                    embedding = embed + \"_Unmod\"\n",
    "                else:\n",
    "                    embedding = embed + \"_Test\" + str(test_mod) + \"_\" + mod\n",
    "                \n",
    "                name = \"Test\" + str(curr_test)\n",
    "                \n",
    "                results = read_weat_results(path,file,name)\n",
    "                if embedding not in exp_results.keys():\n",
    "                    exp_results[embedding] = {}\n",
    "                for key in results:\n",
    "                    exp_results[embedding][key] = results[key]\n",
    "\n",
    "    return exp_results\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all of the data and create the following csv files:\n",
    "* all the results\n",
    "* the concise results\n",
    "* correlations between the concise variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for embed in [\"ft\", \"w2v\"]:\n",
    "    results_path = path+\"csv/\"+embed+\"_\"\n",
    "    results = weat_results(embed,weat_path,None)\n",
    "    results = cnn1_results(embed,cnn_path,results)\n",
    "    results = cnn2_results(embed,cnn_path,results)\n",
    "    df = pd.DataFrame(results, dtype=float).transpose()\n",
    "    df.to_csv(results_path+\"results.csv\")\n",
    "    cols = [col for col in df.columns if ((\"Size\" in col) or (\"f1\" in col) or (\"_EqOpp\" in col) or (\"_DiffPr\" in col) or (\"emr\" in col))]\n",
    "    concise = df[cols]\n",
    "    concise.to_csv(results_path+\"concise.csv\")\n",
    "    corr = concise.corr(method=\"spearman\")\n",
    "    corr.to_csv(results_path+\"correlations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import matplotlib and pyplot for plotting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the nice plots that we saw on the dissertation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embed in [\"ft\", \"w2v\"]:\n",
    "    results_path = path+\"csv/\"+embed+\"_\"\n",
    "    results = weat_results(embed,weat_path,None)\n",
    "    \n",
    "    WEAT = []\n",
    "    Y = []\n",
    "    P = []\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    p = []\n",
    "    \n",
    "    XTICKS = [\"Test \"+str(i) for i in [1,2,6,7,8,9]]\n",
    "    for a,embedding in enumerate(results):\n",
    "        for j,i in enumerate([1,2,6,7,8,9]):\n",
    "            key = \"Test\" + str(i) + \"_EffectSize\"\n",
    "            if a!=0:\n",
    "                WEAT.append(results[embedding][key])\n",
    "            else:\n",
    "                x.append(results[embedding][key])\n",
    "            key = \"Test\" + str(i) + \"_pValue\"\n",
    "            if a!=0:\n",
    "                P.append(results[embedding][key])\n",
    "                Y.append(j)\n",
    "            else:\n",
    "                p.append(results[embedding][key])\n",
    "                y.append(j)\n",
    "            \n",
    "            \n",
    "    cmap = plt.cm.jet\n",
    "    plt.scatter(y,x,facecolors=cmap(p),s=200)\n",
    "    plt.scatter(Y[::-1],WEAT[::-1],facecolors='none',edgecolors=cmap(P[::-1]),s=400)\n",
    "    \n",
    "    sm = plt.colorbar(plt.cm.ScalarMappable(cmap=cmap))\n",
    "    sm.ax.set_ylabel(\"p-Value\")\n",
    "    \n",
    "    embedding = \"FastText\" if embed==\"ft\" else \"word2vec\"\n",
    "    plt.xticks(range(6),XTICKS)\n",
    "    plt.xlabel(\"WEAT tests using \"+embedding)\n",
    "    plt.ylabel(\"Effect Size\")\n",
    "    \n",
    "    plt.savefig(embed + \"_WEAT.png\", dpi=300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
