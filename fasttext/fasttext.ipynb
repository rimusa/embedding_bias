{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 14:29:07,526 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2020-07-06 14:29:07,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-07-06 14:29:07,533 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2020-07-06 14:29:07,533 : INFO : resetting layer weights\n",
      "2020-07-06 14:29:28,388 : INFO : collecting all words and their counts\n",
      "2020-07-06 14:29:28,402 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-07-06 14:29:28,575 : INFO : PROGRESS: at sentence #10000, processed 118198 words, keeping 13287 word types\n",
      "2020-07-06 14:29:28,927 : INFO : PROGRESS: at sentence #20000, processed 233953 words, keeping 19423 word types\n",
      "2020-07-06 14:29:29,105 : INFO : PROGRESS: at sentence #30000, processed 348820 words, keeping 23858 word types\n",
      "2020-07-06 14:29:29,237 : INFO : PROGRESS: at sentence #40000, processed 464660 words, keeping 27310 word types\n",
      "2020-07-06 14:29:29,368 : INFO : PROGRESS: at sentence #50000, processed 583700 words, keeping 30337 word types\n",
      "2020-07-06 14:29:29,540 : INFO : PROGRESS: at sentence #60000, processed 699917 words, keeping 32961 word types\n",
      "2020-07-06 14:29:29,678 : INFO : PROGRESS: at sentence #70000, processed 820036 words, keeping 35311 word types\n",
      "2020-07-06 14:29:29,820 : INFO : PROGRESS: at sentence #80000, processed 940783 words, keeping 37345 word types\n",
      "2020-07-06 14:29:29,991 : INFO : PROGRESS: at sentence #90000, processed 1060350 words, keeping 39187 word types\n",
      "2020-07-06 14:29:30,129 : INFO : PROGRESS: at sentence #100000, processed 1181796 words, keeping 40842 word types\n",
      "2020-07-06 14:29:30,304 : INFO : PROGRESS: at sentence #110000, processed 1302683 words, keeping 42445 word types\n",
      "2020-07-06 14:29:30,451 : INFO : PROGRESS: at sentence #120000, processed 1425324 words, keeping 44000 word types\n",
      "2020-07-06 14:29:30,540 : INFO : PROGRESS: at sentence #130000, processed 1547855 words, keeping 45297 word types\n",
      "2020-07-06 14:29:30,602 : INFO : PROGRESS: at sentence #140000, processed 1669859 words, keeping 46597 word types\n",
      "2020-07-06 14:29:30,655 : INFO : PROGRESS: at sentence #150000, processed 1792576 words, keeping 47822 word types\n",
      "2020-07-06 14:29:30,703 : INFO : PROGRESS: at sentence #160000, processed 1916086 words, keeping 48992 word types\n",
      "2020-07-06 14:29:30,750 : INFO : PROGRESS: at sentence #170000, processed 2039526 words, keeping 49989 word types\n",
      "2020-07-06 14:29:30,800 : INFO : PROGRESS: at sentence #180000, processed 2162971 words, keeping 50960 word types\n",
      "2020-07-06 14:29:30,848 : INFO : PROGRESS: at sentence #190000, processed 2286209 words, keeping 51851 word types\n",
      "2020-07-06 14:29:30,890 : INFO : PROGRESS: at sentence #200000, processed 2407868 words, keeping 52672 word types\n",
      "2020-07-06 14:29:30,932 : INFO : PROGRESS: at sentence #210000, processed 2529973 words, keeping 53469 word types\n",
      "2020-07-06 14:29:30,980 : INFO : PROGRESS: at sentence #220000, processed 2652391 words, keeping 54297 word types\n",
      "2020-07-06 14:29:31,037 : INFO : PROGRESS: at sentence #230000, processed 2771256 words, keeping 54981 word types\n",
      "2020-07-06 14:29:31,082 : INFO : PROGRESS: at sentence #240000, processed 2892067 words, keeping 55643 word types\n",
      "2020-07-06 14:29:31,125 : INFO : PROGRESS: at sentence #250000, processed 3014688 words, keeping 56281 word types\n",
      "2020-07-06 14:29:31,168 : INFO : PROGRESS: at sentence #260000, processed 3136061 words, keeping 56936 word types\n",
      "2020-07-06 14:29:31,213 : INFO : PROGRESS: at sentence #270000, processed 3258869 words, keeping 57542 word types\n",
      "2020-07-06 14:29:31,257 : INFO : PROGRESS: at sentence #280000, processed 3380913 words, keeping 58103 word types\n",
      "2020-07-06 14:29:31,299 : INFO : PROGRESS: at sentence #290000, processed 3500549 words, keeping 58627 word types\n",
      "2020-07-06 14:29:31,344 : INFO : PROGRESS: at sentence #300000, processed 3621422 words, keeping 59112 word types\n",
      "2020-07-06 14:29:31,383 : INFO : PROGRESS: at sentence #310000, processed 3740691 words, keeping 59614 word types\n",
      "2020-07-06 14:29:31,424 : INFO : PROGRESS: at sentence #320000, processed 3860753 words, keeping 60079 word types\n",
      "2020-07-06 14:29:31,465 : INFO : PROGRESS: at sentence #330000, processed 3979190 words, keeping 60509 word types\n",
      "2020-07-06 14:29:31,509 : INFO : PROGRESS: at sentence #340000, processed 4097867 words, keeping 60913 word types\n",
      "2020-07-06 14:29:31,550 : INFO : PROGRESS: at sentence #350000, processed 4213579 words, keeping 61339 word types\n",
      "2020-07-06 14:29:31,589 : INFO : PROGRESS: at sentence #360000, processed 4334588 words, keeping 61809 word types\n",
      "2020-07-06 14:29:31,640 : INFO : PROGRESS: at sentence #370000, processed 4461391 words, keeping 62301 word types\n",
      "2020-07-06 14:29:31,684 : INFO : PROGRESS: at sentence #380000, processed 4586823 words, keeping 62777 word types\n",
      "2020-07-06 14:29:31,780 : INFO : PROGRESS: at sentence #390000, processed 4712869 words, keeping 63221 word types\n",
      "2020-07-06 14:29:31,834 : INFO : PROGRESS: at sentence #400000, processed 4837329 words, keeping 63597 word types\n",
      "2020-07-06 14:29:31,889 : INFO : PROGRESS: at sentence #410000, processed 4963136 words, keeping 63964 word types\n",
      "2020-07-06 14:29:31,940 : INFO : PROGRESS: at sentence #420000, processed 5090788 words, keeping 64316 word types\n",
      "2020-07-06 14:29:31,998 : INFO : PROGRESS: at sentence #430000, processed 5219449 words, keeping 64636 word types\n",
      "2020-07-06 14:29:32,056 : INFO : PROGRESS: at sentence #440000, processed 5348418 words, keeping 64951 word types\n",
      "2020-07-06 14:29:32,119 : INFO : PROGRESS: at sentence #450000, processed 5477466 words, keeping 65251 word types\n",
      "2020-07-06 14:29:32,175 : INFO : PROGRESS: at sentence #460000, processed 5607289 words, keeping 65561 word types\n",
      "2020-07-06 14:29:32,229 : INFO : PROGRESS: at sentence #470000, processed 5738715 words, keeping 65845 word types\n",
      "2020-07-06 14:29:32,282 : INFO : PROGRESS: at sentence #480000, processed 5869356 words, keeping 66117 word types\n",
      "2020-07-06 14:29:32,345 : INFO : PROGRESS: at sentence #490000, processed 6001419 words, keeping 66388 word types\n",
      "2020-07-06 14:29:32,399 : INFO : PROGRESS: at sentence #500000, processed 6133726 words, keeping 66622 word types\n",
      "2020-07-06 14:29:32,446 : INFO : PROGRESS: at sentence #510000, processed 6265649 words, keeping 66855 word types\n",
      "2020-07-06 14:29:32,504 : INFO : PROGRESS: at sentence #520000, processed 6396509 words, keeping 67081 word types\n",
      "2020-07-06 14:29:32,564 : INFO : PROGRESS: at sentence #530000, processed 6528785 words, keeping 67297 word types\n",
      "2020-07-06 14:29:32,619 : INFO : PROGRESS: at sentence #540000, processed 6660200 words, keeping 67499 word types\n",
      "2020-07-06 14:29:32,663 : INFO : PROGRESS: at sentence #550000, processed 6787350 words, keeping 67682 word types\n",
      "2020-07-06 14:29:32,721 : INFO : PROGRESS: at sentence #560000, processed 6916454 words, keeping 67852 word types\n",
      "2020-07-06 14:29:32,782 : INFO : PROGRESS: at sentence #570000, processed 7046211 words, keeping 68011 word types\n",
      "2020-07-06 14:29:32,825 : INFO : PROGRESS: at sentence #580000, processed 7171634 words, keeping 68161 word types\n",
      "2020-07-06 14:29:32,876 : INFO : PROGRESS: at sentence #590000, processed 7295839 words, keeping 68306 word types\n",
      "2020-07-06 14:29:32,930 : INFO : PROGRESS: at sentence #600000, processed 7421948 words, keeping 68450 word types\n",
      "2020-07-06 14:29:32,992 : INFO : PROGRESS: at sentence #610000, processed 7548958 words, keeping 68577 word types\n",
      "2020-07-06 14:29:33,047 : INFO : PROGRESS: at sentence #620000, processed 7677209 words, keeping 68711 word types\n",
      "2020-07-06 14:29:33,099 : INFO : PROGRESS: at sentence #630000, processed 7803625 words, keeping 68855 word types\n",
      "2020-07-06 14:29:33,142 : INFO : PROGRESS: at sentence #640000, processed 7930380 words, keeping 68986 word types\n",
      "2020-07-06 14:29:33,194 : INFO : PROGRESS: at sentence #650000, processed 8056756 words, keeping 69149 word types\n",
      "2020-07-06 14:29:33,257 : INFO : PROGRESS: at sentence #660000, processed 8182733 words, keeping 69289 word types\n",
      "2020-07-06 14:29:33,316 : INFO : PROGRESS: at sentence #670000, processed 8308465 words, keeping 69411 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 14:29:33,369 : INFO : PROGRESS: at sentence #680000, processed 8432881 words, keeping 69548 word types\n",
      "2020-07-06 14:29:33,411 : INFO : PROGRESS: at sentence #690000, processed 8558191 words, keeping 69689 word types\n",
      "2020-07-06 14:29:33,464 : INFO : PROGRESS: at sentence #700000, processed 8681386 words, keeping 69805 word types\n",
      "2020-07-06 14:29:33,521 : INFO : PROGRESS: at sentence #710000, processed 8803783 words, keeping 69914 word types\n",
      "2020-07-06 14:29:33,569 : INFO : PROGRESS: at sentence #720000, processed 8927078 words, keeping 70022 word types\n",
      "2020-07-06 14:29:33,622 : INFO : PROGRESS: at sentence #730000, processed 9045956 words, keeping 70187 word types\n",
      "2020-07-06 14:29:33,672 : INFO : PROGRESS: at sentence #740000, processed 9161170 words, keeping 70323 word types\n",
      "2020-07-06 14:29:33,735 : INFO : PROGRESS: at sentence #750000, processed 9276736 words, keeping 70457 word types\n",
      "2020-07-06 14:29:33,785 : INFO : PROGRESS: at sentence #760000, processed 9391430 words, keeping 70560 word types\n",
      "2020-07-06 14:29:33,827 : INFO : PROGRESS: at sentence #770000, processed 9507510 words, keeping 70646 word types\n",
      "2020-07-06 14:29:33,878 : INFO : PROGRESS: at sentence #780000, processed 9624040 words, keeping 70716 word types\n",
      "2020-07-06 14:29:33,929 : INFO : PROGRESS: at sentence #790000, processed 9742809 words, keeping 70811 word types\n",
      "2020-07-06 14:29:33,981 : INFO : PROGRESS: at sentence #800000, processed 9860965 words, keeping 70894 word types\n",
      "2020-07-06 14:29:34,039 : INFO : PROGRESS: at sentence #810000, processed 9982277 words, keeping 70988 word types\n",
      "2020-07-06 14:29:34,086 : INFO : PROGRESS: at sentence #820000, processed 10104086 words, keeping 71063 word types\n",
      "2020-07-06 14:29:34,140 : INFO : PROGRESS: at sentence #830000, processed 10223721 words, keeping 71144 word types\n",
      "2020-07-06 14:29:34,201 : INFO : PROGRESS: at sentence #840000, processed 10344188 words, keeping 71219 word types\n",
      "2020-07-06 14:29:34,256 : INFO : PROGRESS: at sentence #850000, processed 10466129 words, keeping 71288 word types\n",
      "2020-07-06 14:29:34,298 : INFO : PROGRESS: at sentence #860000, processed 10586187 words, keeping 71352 word types\n",
      "2020-07-06 14:29:34,310 : INFO : collected 71367 word types from a corpus of 10602447 raw words and 861384 sentences\n",
      "2020-07-06 14:29:34,311 : INFO : Loading a fresh vocabulary\n",
      "2020-07-06 14:29:34,464 : INFO : effective_min_count=5 retains 44648 unique words (62% of original 71367, drops 26719)\n",
      "2020-07-06 14:29:34,465 : INFO : effective_min_count=5 leaves 10532140 word corpus (99% of original 10602447, drops 70307)\n",
      "2020-07-06 14:29:34,581 : INFO : deleting the raw counts dictionary of 71367 items\n",
      "2020-07-06 14:29:34,583 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2020-07-06 14:29:34,583 : INFO : downsampling leaves estimated 7626363 word corpus (72.4% of prior 10532140)\n",
      "2020-07-06 14:29:35,020 : INFO : estimated required memory for 44648 words, 217418 buckets and 100 dimensions: 154270952 bytes\n",
      "2020-07-06 14:29:35,027 : INFO : resetting layer weights\n",
      "2020-07-06 14:29:46,284 : INFO : training model with 3 workers on 44648 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-07-06 14:30:13,691 : INFO : EPOCH 1 - PROGRESS: at 33.68% examples, 93120 words/s, in_qsize -1, out_qsize 1\n",
      "2020-07-06 14:30:13,692 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-06 14:30:13,891 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-06 14:30:13,956 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-06 14:30:13,957 : INFO : EPOCH - 1 : training on 10626481 raw words (7645433 effective words) took 27.6s, 276756 effective words/s\n",
      "2020-07-06 14:30:44,384 : INFO : EPOCH 2 - PROGRESS: at 33.68% examples, 83852 words/s, in_qsize -1, out_qsize 3\n",
      "2020-07-06 14:30:44,385 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-06 14:30:44,385 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-06 14:30:44,542 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-06 14:30:44,543 : INFO : EPOCH - 2 : training on 10626481 raw words (7643887 effective words) took 30.5s, 250402 effective words/s\n",
      "2020-07-06 14:31:15,072 : INFO : EPOCH 3 - PROGRESS: at 33.68% examples, 83571 words/s, in_qsize -1, out_qsize 1\n",
      "2020-07-06 14:31:15,073 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-06 14:31:15,278 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-06 14:31:15,395 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-06 14:31:15,395 : INFO : EPOCH - 3 : training on 10626481 raw words (7643576 effective words) took 30.8s, 248193 effective words/s\n",
      "2020-07-06 14:31:51,918 : INFO : EPOCH 4 - PROGRESS: at 33.68% examples, 69822 words/s, in_qsize -1, out_qsize 1\n",
      "2020-07-06 14:31:51,919 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-06 14:31:52,127 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-06 14:31:52,811 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-06 14:31:52,811 : INFO : EPOCH - 4 : training on 10626481 raw words (7641201 effective words) took 37.4s, 204546 effective words/s\n",
      "2020-07-06 14:32:26,719 : INFO : EPOCH 5 - PROGRESS: at 33.68% examples, 75286 words/s, in_qsize -1, out_qsize 1\n",
      "2020-07-06 14:32:26,720 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-06 14:32:26,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-06 14:32:27,704 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-06 14:32:27,704 : INFO : EPOCH - 5 : training on 10626481 raw words (7643854 effective words) took 34.8s, 219552 effective words/s\n",
      "2020-07-06 14:32:27,709 : INFO : training on a 53132405 raw words (38217951 effective words) took 161.4s, 236756 effective words/s\n",
      "2020-07-06 14:32:27,710 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-07-06 14:32:29,196 : INFO : saving FastText object under /tmp/saved_model_gensim-jgqav0tc, separately []\n",
      "2020-07-06 14:32:29,198 : INFO : storing np array 'vectors_ngrams' to /tmp/saved_model_gensim-jgqav0tc.wv.vectors_ngrams.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastText object at 0x7fa0e6868d68>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 14:32:29,834 : INFO : not storing attribute vectors_norm\n",
      "2020-07-06 14:32:29,835 : INFO : not storing attribute vectors_vocab_norm\n",
      "2020-07-06 14:32:29,835 : INFO : not storing attribute vectors_ngrams_norm\n",
      "2020-07-06 14:32:29,836 : INFO : not storing attribute buckets_word\n",
      "2020-07-06 14:32:29,836 : INFO : storing np array 'vectors_ngrams_lockf' to /tmp/saved_model_gensim-jgqav0tc.trainables.vectors_ngrams_lockf.npy\n",
      "2020-07-06 14:32:31,547 : INFO : saved /tmp/saved_model_gensim-jgqav0tc\n",
      "2020-07-06 14:32:31,550 : INFO : loading FastText object from /tmp/saved_model_gensim-jgqav0tc\n",
      "2020-07-06 14:32:32,047 : INFO : loading wv recursively from /tmp/saved_model_gensim-jgqav0tc.wv.* with mmap=None\n",
      "2020-07-06 14:32:32,048 : INFO : loading vectors_ngrams from /tmp/saved_model_gensim-jgqav0tc.wv.vectors_ngrams.npy with mmap=None\n",
      "2020-07-06 14:32:33,210 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-07-06 14:32:33,211 : INFO : setting ignored attribute vectors_vocab_norm to None\n",
      "2020-07-06 14:32:33,211 : INFO : setting ignored attribute vectors_ngrams_norm to None\n",
      "2020-07-06 14:32:33,211 : INFO : setting ignored attribute buckets_word to None\n",
      "2020-07-06 14:32:33,212 : INFO : loading vocabulary recursively from /tmp/saved_model_gensim-jgqav0tc.vocabulary.* with mmap=None\n",
      "2020-07-06 14:32:33,212 : INFO : loading trainables recursively from /tmp/saved_model_gensim-jgqav0tc.trainables.* with mmap=None\n",
      "2020-07-06 14:32:33,213 : INFO : loading vectors_ngrams_lockf from /tmp/saved_model_gensim-jgqav0tc.trainables.vectors_ngrams_lockf.npy with mmap=None\n",
      "2020-07-06 14:32:34,242 : INFO : loaded /tmp/saved_model_gensim-jgqav0tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastText object at 0x7fa052b8bcc0>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from pprint import pprint as print\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Set file names for train and test data\n",
    "# Corpus file should contain path to data file\n",
    "corpus_file = '/home/mugdha/Documents/msc_project/data/archive/2019_03/tweets_processed_1.tsv' \n",
    "\n",
    "model = FT_gensim(size=100,sg=1)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(corpus_file=corpus_file)\n",
    "\n",
    "# train the model\n",
    "model.train(\n",
    "    corpus_file=corpus_file, epochs=model.epochs,\n",
    "    total_examples=model.corpus_count, total_words=model.corpus_total_words\n",
    ")\n",
    "\n",
    "print(model)\n",
    "# saving a model trained via Gensim's fastText implementation\n",
    "import tempfile\n",
    "import os\n",
    "with tempfile.NamedTemporaryFile(prefix='saved_model_gensim-', delete=False) as tmp:\n",
    "    model.save(tmp.name, separately=[])\n",
    "\n",
    "loaded_model = FT_gensim.load(tmp.name)\n",
    "print(loaded_model)\n",
    "\n",
    "os.unlink(tmp.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
